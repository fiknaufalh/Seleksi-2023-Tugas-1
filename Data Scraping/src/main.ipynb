{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web Scraping Watch Product in *jamtangan.com* with Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-requisite:\n",
    "\n",
    "* Have python > 3.0 installed : https://www.python.org/downloads/windows/\n",
    "* Ensure pip or anaconda is installed\n",
    "* Have jupyter notebook installed : https://jupyter.org/install (if using pip) or https://anaconda.org/anaconda/jupyter (if using anaconda)\n",
    "* Have Selenium WebDriver installed : https://pypi.org/project/selenium/ (if using pip) or https://anaconda.org/conda-forge/selenium (if using anaconda)\n",
    "* Have Pandas installed\n",
    "* Download chrome webdriver : https://chromedriver.chromium.org/downloads (make sure it supports your Chrome version!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -r \"../requirements.txt\"\n",
    "# pip install EmailMessage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import csv\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "from email.message import EmailMessage\n",
    "import ssl, smtplib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Email to Send Notification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_start = time.asctime( time.localtime(time.time()) )\n",
    "\n",
    "email_sender = \"18221096@std.stei.itb.ac.id\"\n",
    "email_password = \"<generated>\"\n",
    "email_receiver = \"fikrinaufalh9@gmail.com\"\n",
    "\n",
    "time_end = time.asctime( time.localtime(time.time()) )\n",
    "\n",
    "subject = \"Web Scraping Report\"\n",
    "body = f\"\"\"\n",
    "WEB SCRAPING DONE!!!\n",
    "Time Start: {time_start}\n",
    "Time End: {time_end}\n",
    "\"\"\"\n",
    "\n",
    "email = EmailMessage()\n",
    "email['From'] = email_sender\n",
    "email['To'] = email_receiver\n",
    "email['Subject'] = subject\n",
    "email.set_content(body)\n",
    "\n",
    "context = ssl.create_default_context()\n",
    "\n",
    "with smtplib.SMTP_SSL(\"smtp.gmail.com\", 465, context=context) as smtp:\n",
    "    smtp.login(email_sender, email_password)\n",
    "    smtp.sendmail(email_sender, email_receiver, email.as_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Supporting Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_isoformat(input):\n",
    "    month_dict = {\n",
    "        \"Jan\": \"01\",\n",
    "        \"Feb\": \"02\",\n",
    "        \"Mar\": \"03\",\n",
    "        \"Apr\": \"04\",\n",
    "        \"Mei\": \"05\",\n",
    "        \"Jun\": \"06\",\n",
    "        \"Jul\": \"07\",\n",
    "        \"Ags\": \"08\",\n",
    "        \"Sep\": \"09\",\n",
    "        \"Okt\": \"10\",\n",
    "        \"Nov\": \"11\",\n",
    "        \"Des\": \"12\"\n",
    "    }\n",
    "\n",
    "    for key, value in month_dict.items():\n",
    "        input = input.replace(key, value)\n",
    "    \n",
    "    datetime_object = datetime.strptime(input, \"%d %m %Y, %H:%M WIB\")\n",
    "\n",
    "    date = datetime_object.date()\n",
    "    time = datetime_object.time()\n",
    "\n",
    "    return [date, time]\n",
    "\n",
    "def to_email(name):\n",
    "    name = name.lower().strip()\n",
    "    email = name.replace(\" \", \"\") + \"@gmail.com\"\n",
    "    return email\n",
    "\n",
    "def csv_to_json(csvFilePath, jsonFilePath):\n",
    "    jsonArray = []\n",
    "\n",
    "    #Menulis file csv\n",
    "    with open(csvFilePath, encoding='utf-8') as csvf: \n",
    "        #Me-load file csv menggunakan library dictionary reader\n",
    "        csvReader = csv.DictReader(csvf) \n",
    "\n",
    "        #Mengubah setiap baris csv menjadi dictionary python\n",
    "        for row in csvReader: \n",
    "            #Menambah python dictionary ini ke array jsonArray\n",
    "            jsonArray.append(row)\n",
    "\n",
    "    #Mengubah jsonArray menjadi JSON String dan menulis ke dalam file\n",
    "    with open(jsonFilePath, 'w', encoding='utf-8') as jsonf: \n",
    "        jsonString = json.dumps(jsonArray, indent=4)\n",
    "        jsonf.write(jsonString)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract Product Table Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_product(driver):\n",
    "    product_dict = {\n",
    "        \"Brand\" : \"\",\n",
    "        \"Model No\" : \"\",\n",
    "        \"Series\" : \"\",\n",
    "        \"Gender\" : \"\",\n",
    "        \"Colour\" : \"\",\n",
    "        \"Luminous\" : \"\",\n",
    "        \"Calendar\" : \"\",\n",
    "        \"Water Resistance\" : \"\",\n",
    "        \"Movement\" : \"\",\n",
    "        \"Weight after packing\" : \"\",\n",
    "        \"Case Diameter\" : \"\",\n",
    "        \"Strap Material\" : \"\",\n",
    "    }\n",
    "\n",
    "    spec_grid = driver.find_element(By.CSS_SELECTOR, \".tab-content .grid\")\n",
    "    spec_list = spec_grid.find_elements(By.CSS_SELECTOR, \".spec-item\")\n",
    "    for spec in spec_list:\n",
    "        if spec.find_element(By.CSS_SELECTOR, \".font-black\").text in product_dict.keys():\n",
    "            data = spec.find_elements(By.CSS_SELECTOR, \".leading-6\")\n",
    "            key = data[0].text.strip()\n",
    "            value = data[1].text.strip()\n",
    "            product_dict[key] = value\n",
    "    \n",
    "    return product_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract Sales Table Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sales(driver):\n",
    "    sales_dict = {\n",
    "        \"Product Name\" : \"\",\n",
    "        \"Brand\" : \"\",\n",
    "        \"Model No\" : \"\",\n",
    "        \"Normal Price\" : \"\",\n",
    "        \"Discounted Price\" : \"\",\n",
    "        \"Discount Percentage\" : \"\",\n",
    "        \"Number of Seen\" : \"\",\n",
    "        \"Number of Sold\" : \"\",\n",
    "        \"Offline Stock Status\" : \"\",\n",
    "        \"Online Stock Status\" : \"\",\n",
    "    }\n",
    "\n",
    "    spec_grid = driver.find_element(By.CSS_SELECTOR, \".tab-content .grid\")\n",
    "    spec_list_raw = spec_grid.find_elements(By.CSS_SELECTOR, \".spec-item\")\n",
    "    for spec in spec_list_raw:\n",
    "        if spec.find_element(By.CSS_SELECTOR, \".font-black\").text in [\"Brand\", \"Model No\"]:\n",
    "            data = spec.find_elements(By.CSS_SELECTOR, \".leading-6\")\n",
    "            key = data[0].text.strip()\n",
    "            value = data[1].text.strip()\n",
    "            sales_dict[key] = value\n",
    "\n",
    "    sales_dict[\"Product Name\"] = driver.find_element(By.TAG_NAME, \"h1\").text.strip()\n",
    "\n",
    "    try:\n",
    "        normal_price = driver.find_element(By.CSS_SELECTOR, \"div[data-testid='test-product-info'] .line-through\").text.strip()\n",
    "    except:\n",
    "        normal_price = driver.find_element(By.CSS_SELECTOR, \"div[data-testid='test-product-info'] .text-xl\").text.strip()\n",
    "    discounted_price = driver.find_element(By.CSS_SELECTOR, \"div[data-testid='test-product-info'] .text-xl\").text.strip()\n",
    "    sales_dict[\"Normal Price\"] = int(normal_price.replace(\"Rp\", \"\").replace(\".\", \"\").strip())\n",
    "    sales_dict[\"Discounted Price\"] = int(discounted_price.replace(\"Rp\", \"\").replace(\".\", \"\").strip())\n",
    "\n",
    "    discount_percentage = (sales_dict[\"Normal Price\"] - sales_dict[\"Discounted Price\"]) / sales_dict[\"Normal Price\"]\n",
    "    sales_dict[\"Discount Percentage\"] = round(discount_percentage * 100, 4)\n",
    "\n",
    "    num_seen = driver.find_element(By.CSS_SELECTOR, \".ic-eye + div > .text-sm\").text.strip()\n",
    "    if (num_seen.__contains__(\"Rb\")):\n",
    "        num_seen = float(num_seen.replace(\" Rb\", \"\").strip()) * 1000\n",
    "    sales_dict[\"Number of Seen\"] = int(num_seen)\n",
    "\n",
    "    num_sold = driver.find_element(By.CSS_SELECTOR, \".ic-cart.mr-1 + div > .text-sm\").text.strip()\n",
    "    if (num_sold.__contains__(\"Rb\")):\n",
    "        num_sold = float(num_sold.replace(\" Rb\", \"\").strip()) * 1000\n",
    "    sales_dict[\"Number of Sold\"] = int(num_sold)\n",
    "\n",
    "    try:\n",
    "        empty_badge = driver.find_element(By.CSS_SELECTOR, \".badge.bg-accent-red\")\n",
    "        if (empty_badge != None and empty_badge.text.strip().__contains__(\"habis\")):\n",
    "            sales_dict[\"Online Stock Status\"] = \"Not Available\"\n",
    "        else:\n",
    "            raise Exception(\"The badge is not empty badge\")\n",
    "    except:\n",
    "        online_stock_status = driver.find_element(By.CSS_SELECTOR, \".stepper-wrapper + div\").text.strip()\n",
    "        if (online_stock_status == \"STOK ONLINE < 5 PCS\"): sales_dict[\"Online Stock Status\"] = \"Low (< 5 PCS)\"\n",
    "        elif (online_stock_status == \"STOK ONLINE > 5 PCS\"): sales_dict[\"Online Stock Status\"] = \"High (>= 5 PCS)\"\n",
    "        else: sales_dict[\"Online Stock Status\"] = \"Unknown\"\n",
    "\n",
    "    try:\n",
    "        offline_empty = driver.find_element(By.CSS_SELECTOR, \"picture.mr-2 + div\")\n",
    "        if (offline_empty != None and offline_empty.text.strip().__contains__(\"Tidak tersedia\")):\n",
    "            sales_dict[\"Offline Stock Status\"] = \"Not Available\"\n",
    "        else:\n",
    "            raise Exception(\"The text is not empty text\")\n",
    "    except:\n",
    "        try:\n",
    "            offline_stock_status = driver.find_element(By.CSS_SELECTOR, \"div[data-testid='store-item-0']\")\n",
    "            if (offline_stock_status != None):\n",
    "                sales_dict[\"Offline Stock Status\"] = \"Available\"\n",
    "        except:\n",
    "            sales_dict[\"Offline Stock Status\"] = \"Unknown\"\n",
    "\n",
    "    return sales_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract Customer and Review Table Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_customer_review(driver):\n",
    "    customer_dict = {\n",
    "        \"Email\" : \"\",\n",
    "        \"Name\" : \"\",\n",
    "        \"Member Status\" : \"\"\n",
    "    }\n",
    "    customer_header = customer_dict.keys()\n",
    "    customer_list = []\n",
    "\n",
    "    review_dict = {\n",
    "        \"ID Review\" : \"\",\n",
    "        \"Product Name\" : \"\",\n",
    "        \"Email\" : \"\",\n",
    "        \"Date\" : \"\",\n",
    "        \"Time\" : \"\",\n",
    "        \"Rating\" : \"\",\n",
    "        \"Delivery Review\" : \"\",\n",
    "        \"Product Review\" : \"\"\n",
    "    }\n",
    "    review_header = review_dict.keys()\n",
    "    review_list = []\n",
    "\n",
    "    MAX_REVIEW_PER_PRODUCT = 5\n",
    "    div_review_pagination = driver.find_element(By.CSS_SELECTOR, \".pb-14\")\n",
    "    try:\n",
    "        max_tab_per_product = int(div_review_pagination.find_elements(By.TAG_NAME, \"li\")[-2].text)\n",
    "    except:\n",
    "        max_tab_per_product = 1\n",
    "\n",
    "    review_count = 0\n",
    "    tab_count = 0\n",
    "    while (review_count < MAX_REVIEW_PER_PRODUCT and tab_count < max_tab_per_product):\n",
    "        time.sleep(1)\n",
    "        div_review_pagination = driver.find_element(By.CSS_SELECTOR, \".pb-14\")\n",
    "        review_divs = div_review_pagination.find_elements(By.XPATH, \"preceding-sibling::*[position() <= 3]\")\n",
    "\n",
    "        for review in review_divs:\n",
    "            reviewer_name = review.find_element(By.CSS_SELECTOR, \".mb-1 .text-base\").text\n",
    "            if reviewer_name[1] == '*' and reviewer_name[-2] == '*': continue\n",
    "\n",
    "            product_name = driver.find_element(By.CSS_SELECTOR, \"h1\").text\n",
    "\n",
    "            rating = len(review.find_elements(By.CSS_SELECTOR, \".rating .ic-star-fill\"))\n",
    "            datetime_review = to_isoformat(review.find_element(By.CSS_SELECTOR, \"span.block.text-xxs\").text)\n",
    "            date_review, time_review = datetime_review[0], datetime_review[1]\n",
    "            \n",
    "            paragraph_review = review.find_elements(By.CSS_SELECTOR, \"p\")\n",
    "            delivery_review = \"\"\n",
    "            product_review = \"\"\n",
    "            for par in paragraph_review:\n",
    "                title = par.find_element(By.CSS_SELECTOR, \"span\").text\n",
    "                if title == \"Pengiriman:\": delivery_review = par.text.lstrip(\"Pengiriman: \")\n",
    "                if title == \"Produk:\": product_review = par.text.lstrip(\"Produk: \")\n",
    "                else: continue\n",
    "            if delivery_review == \"\": delivery_review = \"Tidak ada review\"\n",
    "            if product_review == \"\": product_review = \"Tidak ada review\"\n",
    "\n",
    "            member_status = driver.find_element(By.CSS_SELECTOR, \".badge.text-xxs\").text\n",
    "\n",
    "            review_count += 1\n",
    "            if review_count > MAX_REVIEW_PER_PRODUCT: break\n",
    "\n",
    "            customer_result = [to_email(reviewer_name), reviewer_name, member_status]\n",
    "            for key, value in zip(customer_header, customer_result):\n",
    "                customer_dict[key] = value\n",
    "            customer_list.append(customer_dict.copy())\n",
    "        \n",
    "            result_review = [review_count, product_name, to_email(reviewer_name), date_review, time_review, rating, delivery_review, product_review]\n",
    "            for key, value in zip(review_header, result_review):\n",
    "                review_dict[key] = value\n",
    "            review_list.append(review_dict.copy())\n",
    "        \n",
    "        tab_count += 1\n",
    "        div_review_pagination = driver.find_element(By.CSS_SELECTOR, \".pb-14\")\n",
    "        page_buttons = div_review_pagination.find_elements(By.TAG_NAME, \"li\")\n",
    "        for page_button in page_buttons:\n",
    "            if page_button.text == str(tab_count + 1): \n",
    "                page_button.click()\n",
    "                break\n",
    "\n",
    "    return [customer_list, review_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the driver\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "\n",
    "# define the URL\n",
    "URL = \"https://www.jamtangan.com/c/jam-tangan\"\n",
    "\n",
    "# open the URL\n",
    "driver.maximize_window()\n",
    "driver.get(URL)\n",
    "\n",
    "# close the pop-up\n",
    "try:\n",
    "    if (driver.find_element(By.ID, \"driver-popover-item\")):\n",
    "        driver.find_element(By.CLASS_NAME, \"driver-close-btn\").click()\n",
    "\n",
    "    time.sleep(3)\n",
    "    if (driver.find_element(By.CSS_SELECTOR, \"button.ng-binding\")):\n",
    "        driver.find_element(By.CSS_SELECTOR, \"button.ng-binding\").click()\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# expand the brands list in filter sidebar\n",
    "expand_brand = driver.find_elements(By.CSS_SELECTOR, \".accordion-content-wrapper .cursor-pointer\")[1]\n",
    "while(expand_brand.text == \"LIHAT LAINNYA\"):\n",
    "    expand_brand.click()\n",
    "    time.sleep(1)\n",
    "    expand_brand = driver.find_elements(By.CSS_SELECTOR, \".accordion-content-wrapper .cursor-pointer\")[1]\n",
    "\n",
    "# get the brands name and url\n",
    "brands_raw = driver.find_elements(By.CSS_SELECTOR, \".accordion-content-wrapper\")[1].find_elements(By.TAG_NAME, \"li\")\n",
    "eliminate = ['Semua Brand', 'Band', 'Strap', 'Bracelet', 'Accessories', 'Jewelry', 'Wallets']\n",
    "brands = []\n",
    "for brand in brands_raw:\n",
    "    eliminated = False\n",
    "    for phrase in eliminate:\n",
    "        if (phrase in brand.find_element(By.TAG_NAME, \"label\").text):\n",
    "            eliminated = True\n",
    "            break\n",
    "    if not eliminated:\n",
    "        brands.append(brand)\n",
    "\n",
    "brands_name = [brand.find_element(By.TAG_NAME, \"label\").text for brand in brands]\n",
    "brands_url = [brand.find_element(By.TAG_NAME, \"a\").get_attribute(\"href\") for brand in brands]\n",
    "num_brands = len(brands)\n",
    "\n",
    "print(\"Number of brands: \", num_brands)\n",
    "\n",
    "product = []\n",
    "sales = []\n",
    "customer = []\n",
    "review = []\n",
    "\n",
    "for brand_url in brands_url:\n",
    "    driver.get(brand_url)\n",
    "    time.sleep(1)\n",
    "    products_url = driver.find_elements(By.CSS_SELECTOR, \"a[data-testid='product-card-test']\").get_attribute(\"href\")\n",
    "    for product_url in products_url:\n",
    "        driver.get(product_url)\n",
    "        product.append(extract_product(driver))\n",
    "        sales.append(extract_sales(driver))\n",
    "        customer.append(extract_customer_review(driver)[0])\n",
    "        review.append(extract_customer_review(driver)[1])\n",
    "\n",
    "    time.sleep(1)\n",
    "\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approximating the amount of pages to scrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # get the number of page for each brand\n",
    "pages = []\n",
    "for i in range(num_brands):\n",
    "    driver.get(brands_url[i])\n",
    "    time.sleep(1)\n",
    "    try:\n",
    "        page = driver.find_element(By.CSS_SELECTOR, \".qa-product-list-pagination\").find_elements(By.TAG_NAME, \"li\")\n",
    "        num_page = len(page) - 2\n",
    "    except:\n",
    "        num_page = 1\n",
    "    pages.append(num_page)\n",
    "    print(f\"Number of page for {brands_name[i]}: \", num_page)\n",
    "\n",
    "# print(\"Number of pages: \", sum(pages))\n",
    "# print(\"Average number of page: \", np.mean(pages))\n",
    "# print(\"Max number of page: \", np.max(pages))\n",
    "# print(\"Min number of page: \", np.min(pages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 1, 7, 7, 5, 1, 1, 1, 1, 1, 1, 1, 5, 1, 1, 1, 4, 1, 7, 4, 2, 7, 5, 4, 1, 1, 1, 1, 7, 7, 1, 1, 1, 7, 2, 1, 1, 1, 1, 4, 1, 1, 7, 1, 1, 1, 2, 1, 1, 5, 2, 1, 1, 1, 3, 7, 4, 6, 7, 6, 3, 1, 1, 1, 2, 4, 1, 2, 1, 7, 1, 1, 7, 3, 3, 4, 2, 7, 7, 1, 4, 1, 1, 1, 1]\n",
      "[2, 1, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 3, 1, 3, 3, 2, 3, 3, 3, 1, 1, 1, 1, 3, 3, 1, 1, 1, 3, 2, 1, 1, 1, 1, 3, 1, 1, 3, 1, 1, 1, 2, 1, 1, 3, 2, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 2, 3, 1, 2, 1, 3, 1, 1, 3, 3, 3, 3, 2, 3, 3, 1, 3, 1, 1, 1, 1]\n",
      "Sum = 157\n",
      "Mean = 1.8470588235294119\n",
      "Page 1 = 45\n",
      "Page 2 = 8\n",
      "Page 3 = 32\n",
      "Max page to scrap = 6280\n"
     ]
    }
   ],
   "source": [
    "print(pages)\n",
    "cut = []\n",
    "for page in pages:\n",
    "    if (page > 3):\n",
    "        cut.append(3)\n",
    "    else:\n",
    "        cut.append(page)\n",
    "print(cut)\n",
    "print(f\"Sum = {sum(cut)}\")\n",
    "print(f\"Mean = {np.mean(cut)}\")\n",
    "freq = [0, 0, 0]\n",
    "for page in cut:\n",
    "    freq[page-1] += 1\n",
    "\n",
    "print(f\"Page 1 = {freq[0]}\")\n",
    "print(f\"Page 2 = {freq[1]}\")\n",
    "print(f\"Page 3 = {freq[2]}\")\n",
    "\n",
    "max_page = freq[0] * 40 + freq[1] * 80 + freq[2] * 120\n",
    "print(f\"Max page to scrap = {max_page}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 1, 7, 7, 5, 1, 1, 1, 1, 1, 1, 1, 5, 1, 1, 1, 4, 1, 7, 4, 2, 7, 5, 4, 1, 1, 1, 1, 7, 7, 1, 1, 1, 7, 2, 1, 1, 1, 1, 4, 1, 1, 7, 1, 1, 1, 2, 1, 1, 5, 2, 1, 1, 1, 3, 7, 4, 6, 7, 6, 3, 1, 1, 1, 2, 4, 1, 2, 1, 7, 1, 1, 7, 3, 3, 4, 2, 7, 7, 1, 4, 1, 1, 1, 1]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Sum = 85\n",
      "Mean = 1.0\n",
      "Page 1 = 85\n",
      "Page 2 = 0\n",
      "Page 3 = 0\n",
      "Max page to scrap = 3400\n"
     ]
    }
   ],
   "source": [
    "print(pages)\n",
    "cut = []\n",
    "for page in pages:\n",
    "    if (page > 1):\n",
    "        cut.append(1)\n",
    "    else:\n",
    "        cut.append(page)\n",
    "print(cut)\n",
    "print(f\"Sum = {sum(cut)}\")\n",
    "print(f\"Mean = {np.mean(cut)}\")\n",
    "freq = [0, 0, 0]\n",
    "for page in cut:\n",
    "    freq[page-1] += 1\n",
    "\n",
    "print(f\"Page 1 = {freq[0]}\")\n",
    "print(f\"Page 2 = {freq[1]}\")\n",
    "print(f\"Page 3 = {freq[2]}\")\n",
    "\n",
    "max_page = freq[0] * 40 + freq[1] * 80 + freq[2] * 120\n",
    "print(f\"Max page to scrap = {max_page}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
